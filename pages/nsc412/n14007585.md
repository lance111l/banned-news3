### 科技领袖警告：AI带给人类灭绝风险堪比核战
------------------------

#### [首页](https://github.com/gfw-breaker/banned-news3/blob/master/README.md) &nbsp;&nbsp;|&nbsp;&nbsp; [法轮功真相](https://github.com/begood0513/basic/blob/master/README.md)  &nbsp;&nbsp;|&nbsp;&nbsp; [手把手翻墙教程](https://github.com/gfw-breaker/guides/wiki)  &nbsp;&nbsp;|&nbsp;&nbsp; [一键翻墙软件](https://github.com/gfw-breaker/nogfw/blob/master/README.md)  



<div><img alt="科技领袖警告：AI带给人类灭绝风险堪比核战" class="attachment-djy_600_400 size-djy_600_400 wp-post-image" src="https://i.epochtimes.com/assets/uploads/2023/04/id13982134-611540-600x400.jpg"/>
<div class="caption">
 图为示意图。(Pixabay)
</div></div><hr/>

#### [ 🎬  免翻墙浏览墙外禁闻、观看YouTube热门视频及电视直播](https://github.com/gfw-breaker/HelloWorld)

#### [ 💥  禁书下载（政治、经济、人权、民主自由、文革、六四 ...）](https://github.com/gfw-breaker/books/blob/master/README.md)

<div><p>
 【大纪元2023年06月01日讯】（大纪元记者高杉编译报导）奥特曼和其他一些
 <ok href="https://www.epochtimes.com/gb/tag/%E7%A7%91%E6%8A%80.html">
  科技
 </ok>
 界
 <ok href="https://www.epochtimes.com/gb/tag/%E9%A2%86%E8%A2%96.html">
  领袖
 </ok>
 警告说，
 <ok href="https://www.epochtimes.com/gb/tag/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD.html">
  人工智能
 </ok>
 （AI）可能给人类带来灭绝的风险，与爆发
 <ok href="https://www.epochtimes.com/gb/tag/%E6%A0%B8%E6%88%98.html">
  核战
 </ok>
 争的后果相当。
</p>
<p>
 <ok href="https://www.epochtimes.com/gb/tag/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD.html">
  人工智能
 </ok>
 行业专家和
 <ok href="https://www.epochtimes.com/gb/tag/%E7%A7%91%E6%8A%80.html">
  科技
 </ok>
 <ok href="https://www.epochtimes.com/gb/tag/%E9%A2%86%E8%A2%96.html">
  领袖
 </ok>
 在一封公开信中表示，人工智能可能导致
 <ok href="https://www.epochtimes.com/gb/tag/%E4%BA%BA%E7%B1%BB%E7%81%AD%E7%BB%9D.html">
  人类灭绝
 </ok>
 。而减少与该技术有关的风险，应该是全球的优先事项。
</p>
<p>
 于周二（5月30日）发表的这份声明中写道：“降低人工智能带给
 <ok href="https://www.epochtimes.com/gb/tag/%E4%BA%BA%E7%B1%BB%E7%81%AD%E7%BB%9D.html">
  人类灭绝
 </ok>
 的风险，与其它规模的社会风险——如疫情和
 <ok href="https://www.epochtimes.com/gb/tag/%E6%A0%B8%E6%88%98.html">
  核战
 </ok>
 争——相比，应该是一个全球优先事项。”
</p>
<p>
 OpenAI公司是人工智能聊天机器人ChatGPT的制造商。该公司首席执行官山姆‧奥特曼（Sam Altman），以及谷歌人工智能部门DeepMind和微软的高管，都支持并签署了这份人工智能安全中心（Center for AI Safety）的简短声明。
</p>
<p>
 在聊天机器人ChatGPT于2022年11月份公开发布、并供公众使用后，该人工智能技术在随后的数月内迅速走红，而且发展速度变得更快。
</p>
<p>
 在发布后的短短两个月内，ChatGPT的用户数量就达到了1亿。该人工智能聊天机器人能够对用户的提示，作出类似人类的反应，该能力让研究人员和公众感到惊讶。这表明，人工智能完全可以模仿人类，并取代人类完成工作。
</p>
<p>
 周二的这份声明说，关于“人工智能带来广泛的、重要和紧迫的风险”的讨论越来越多，但这些讨论可能“很难涉及到最先进的人工智能可能导致的、最严重的风险”，而发布该声明的目的，就是要克服这一障碍，开启对该问题的讨论。
</p>
<p>
 可以说，ChatGPT引发了人们对人工智能的更多的认识和兴趣。现在，世界各地的主要科技公司，都在竞相开发旨在超越竞争对手的AI产品和AI能力。
</p>
<p>
 奥特曼在3月曾承认，他本人对人工智能感到“有点害怕”。因为他担心专制政权会开发和利用这种技术。其他一些科技领袖，如特斯拉公司的埃隆‧马斯克（Elon Musk）和前谷歌首席执行官埃里克‧施密特（Eric Schmidt）等等，也都对人工智能可能给社会带来的风险提出了警告。
</p>
<p>
 在3月份的一封公开信中，马斯克、苹果公司联合创始人史蒂夫‧沃兹尼亚克（Steve Wozniak），以及一些科技界领袖敦促人工智能研究实验室，停止训练比GPT-4更强大的AI系统。GPT-4是OpenAI公司外界所知的、最新最大型的语言模型。他们还呼吁将这种针对更高级人工智能的开发工作暂停六个月。
</p>
<p>
 信中说：“当代人工智能系统已开始在一般任务上与人类展开竞争。”
</p>
<p>
 信中问道：“我们是否应该把所有的工作都自动化，包括那些能够带来成就感的工作？我们是否应该开发非人类的大脑？它们的数量最终可能会超过我们，它们的智慧最终会胜过我们，它们能够最终淘汰和取代我们。我们是否应该冒着失去对我们文明控制的风险去开发它们？”
</p>
<p>
 在上周，施密特再次警告说，随着人工智能技术的发展，人类将面对与AI相关的“生存风险”。
</p>
<p>
 责任编辑：叶紫微#
</p>
</div>
<hr/>
手机上长按并复制下列链接或二维码分享本文章：<br/>
https://github.com/gfw-breaker/banned-news3/blob/master/pages/nsc412/n14007585.md <br/>
<a href='https://github.com/gfw-breaker/banned-news3/blob/master/pages/nsc412/n14007585.md'><img src='https://github.com/gfw-breaker/banned-news3/blob/master/pages/nsc412/n14007585.md.png'/></a> <br/>
原文地址（需翻墙访问）：https://www.epochtimes.com/gb/23/5/31/n14007585.htm


------------------------
#### [首页](https://github.com/gfw-breaker/banned-news3/blob/master/README.md) &nbsp;|&nbsp; [一键翻墙软件](https://github.com/gfw-breaker/nogfw/blob/master/README.md) &nbsp;| [《九评共产党》](https://github.com/gfw-breaker/9ping.md/blob/master/README.md#九评之一评共产党是什么) | [《解体党文化》](https://github.com/gfw-breaker/jtdwh.md/blob/master/README.md) | [《共产主义的终极目的》](https://github.com/gfw-breaker/gczydzjmd.md/blob/master/README.md)


<img src='http://gfw-breaker.win/banned-news3/pages/nsc412/n14007585.md' width='0px' height='0px'/>