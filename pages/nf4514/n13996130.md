### “AI教父”再警告：人类需找到控制AI的方法
------------------------

#### [首页](https://github.com/gfw-breaker/banned-news3/blob/master/README.md) &nbsp;&nbsp;|&nbsp;&nbsp; [法轮功真相](https://github.com/begood0513/basic/blob/master/README.md)  &nbsp;&nbsp;|&nbsp;&nbsp; [手把手翻墙教程](https://github.com/gfw-breaker/guides/wiki)  &nbsp;&nbsp;|&nbsp;&nbsp; [一键翻墙软件](https://github.com/gfw-breaker/nogfw/blob/master/README.md)  



<div><img alt="“AI教父”再警告：人类需找到控制AI的方法" class="attachment-djy_600_400 size-djy_600_400 wp-post-image" src="https://i.epochtimes.com/assets/uploads/2023/04/id13982134-611540-600x400.jpg"/>
<div class="caption">
 图为人工智慧示意图。（Pixabay）
</div></div><hr/>

#### [ 🎬  免翻墙浏览墙外禁闻、观看YouTube热门视频及电视直播](https://github.com/gfw-breaker/HelloWorld)

#### [ 💥  禁书下载（政治、经济、人权、民主自由、文革、六四 ...）](https://github.com/gfw-breaker/books/blob/master/README.md)

<div><p>
 【大纪元2023年05月14日讯】（大纪元记者高杉编译报导）被称为“
 <ok href="https://www.epochtimes.com/gb/tag/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD.html">
  人工智能
 </ok>
 教父”的
 <ok href="https://www.epochtimes.com/gb/tag/%E8%BE%9B%E9%A1%BF.html">
  辛顿
 </ok>
 预测称，人工智能只需5到20年，就能超越
 <ok href="https://www.epochtimes.com/gb/tag/%E4%BA%BA%E7%B1%BB.html">
  人类
 </ok>
 的智慧。而在此之前，人类需要找到控制它的方法。
</p>
<p>
 杰弗里‧
 <ok href="https://www.epochtimes.com/gb/tag/%E8%BE%9B%E9%A1%BF.html">
  辛顿
 </ok>
 （Geoffrey Hinton）最近辞去了谷歌工程副总裁的职务，并为
 <ok href="https://www.epochtimes.com/gb/tag/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD.html">
  人工智能
 </ok>
 将带来的危险而大声疾呼。他在于周五（5月12日）发表的一篇采访中再次警告说，随着人工智能的不断发展，世界需要找到一种方法，来控制这项新技术。
</p>
<p>
 这名“人工智能教父”通过在线视频会议对《国家报》（EL PAÍS）表示，他认为，只发出一封公开信，呼吁在6个月内暂停训练那些比OpenAI开发的GPT-4更强大人工智能系统，是“完全天真”的。而他所能建议的是，那些拥有非常聪明头脑的人，应该努力想出“如何控制这些东西的危险”的方法。
</p>
<p>
 辛顿表示：“人工智能是一项神奇的技术——它在医学、新材料的开发、预测地震或洪水方面，带来了巨大的进步……但我们仍需要作大量的工作，来了解如何遏制人工智能。”
</p>
<p>
 他说：“被动地等待人工智能胜过我们是毫无用处的。我们必须在其发展过程中就控制它。我们还必须了解如何遏制它，如何避免它带来的负面后果。”
</p>
<p>
 例如，辛顿认为，所有政府都一定要对人工智能制出的虚假图片、图像进行标记。
</p>
<p>
 这位科学家说，现在能做的最好的事情，就是“在开发这项技术的同时，我们要投入同样多的精力，来确保它的安全性”。但他说，目前根本没有人去这样做。
</p>
<p>
 当被问及他与同事分享对人工智能问题的担忧时，辛顿说，他认识的许多最聪明的人，都对该问题“严重关切”。
</p>
<p>
 他问道：“我们已经进入了完全未知的领域。我们有能力建造比我们自己更强大的机器，我们仍在掌控一切。但如果我们开发出比我们更聪明的机器呢？我们没有应对这些东西的经验。”
</p>
<p>
 辛顿说，人工智能能够带来许多不同的危险。他列举了就业减少和制作假新闻等等。辛顿指出，他现在认为，人工智能能够比人脑更有效地做事情，像ChatGPT这样的模型，有能力短时间内查阅比
 <ok href="https://www.epochtimes.com/gb/tag/%E4%BA%BA%E7%B1%BB.html">
  人类
 </ok>
 多几千倍的数据。
</p>
<p>
 他说：“这就是让我感到害怕的地方。”
</p>
<p>
 辛顿说，在一个粗略的预估中——他说自己对这个预估不是很有信心——人工智能将需要5到20年的时间，来超越人类的智慧。”
</p>
<p>
 在被问道，人工智能最终是否会拥有自己的目的或目标时，辛顿回答说：“这是一个关键问题，也许是这项技术能够带来的最大危险。”
</p>
<p>
 “所以，最大的问题是，我们是否能够确保人工智能拥有对我们有利的目标？这就是所谓的对齐问题。而我们有多个理由，解释为何要对此非常关注。”
</p>
<p>
 他解释说：“首先是，总会有一些人想要创造人工智能机器人战士。你不认为，如果可以的话，普京会去开发它们吗？如果你能让机器有能力产生出自主的目标，你就可以更有效地做到这一点。而在这种情况下，如果机器是智能的，它很快就会意识到，如果它变得更强大，就能更好地实现它的目标。”
</p>
<p>
 辛顿断言：“我们有可能无法避免一个糟糕的结局……但也很明显，我们有机会为这个挑战做好准备。我们需要大量有创造力和智慧的人。如果有任何方法可以控制人工智能，我们需要在它变得过于聪明之前，找到这个方法。”
</p>
<p>
 责任编辑：林妍 #
</p>
</div>
<hr/>
手机上长按并复制下列链接或二维码分享本文章：<br/>
https://github.com/gfw-breaker/banned-news3/blob/master/pages/nf4514/n13996130.md <br/>
<a href='https://github.com/gfw-breaker/banned-news3/blob/master/pages/nf4514/n13996130.md'><img src='https://github.com/gfw-breaker/banned-news3/blob/master/pages/nf4514/n13996130.md.png'/></a> <br/>
原文地址（需翻墙访问）：https://www.epochtimes.com/gb/23/5/13/n13996130.htm


------------------------
#### [首页](https://github.com/gfw-breaker/banned-news3/blob/master/README.md) &nbsp;|&nbsp; [一键翻墙软件](https://github.com/gfw-breaker/nogfw/blob/master/README.md) &nbsp;| [《九评共产党》](https://github.com/gfw-breaker/9ping.md/blob/master/README.md#九评之一评共产党是什么) | [《解体党文化》](https://github.com/gfw-breaker/jtdwh.md/blob/master/README.md) | [《共产主义的终极目的》](https://github.com/gfw-breaker/gczydzjmd.md/blob/master/README.md)


<img src='http://gfw-breaker.win/banned-news3/pages/nf4514/n13996130.md' width='0px' height='0px'/>