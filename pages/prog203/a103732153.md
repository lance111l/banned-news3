### 谷歌全球推广AI  却限制自家员工使用
------------------------

#### [首页](https://github.com/gfw-breaker/banned-news3/blob/master/README.md) &nbsp;&nbsp;|&nbsp;&nbsp; [法轮功真相](https://github.com/begood0513/basic/blob/master/README.md)  &nbsp;&nbsp;|&nbsp;&nbsp; [手把手翻墙教程](https://github.com/gfw-breaker/guides/wiki)  &nbsp;&nbsp;|&nbsp;&nbsp; [一键翻墙软件](https://github.com/gfw-breaker/nogfw/blob/master/README.md)  



<div><div class="featured_image">
 <figure>
  <img alt="谷歌全球推广AI  却限制自家员工使用" src="https://i.ntdtv.com/assets/uploads/2023/06/id103732159-GettyImages-1253640015-800x450.jpg"/>
 </figure><br/>
 <span class="caption">
  2023年5月10日，在加州的Google开发者大会上，录音艺术家Dan Deacon与一只化装的鸟一起表演。( JOSH EDELSON/AFP via Getty Images)
 </span>
</div>
</div><hr/>

#### [ 🎬  免翻墙浏览墙外禁闻、观看YouTube热门视频及电视直播](https://github.com/gfw-breaker/HelloWorld)

#### [ 💥  禁书下载（政治、经济、人权、民主自由、文革、六四 ...）](https://github.com/gfw-breaker/books/blob/master/README.md)

<div><div class="post_content" itemprop="articleBody">
 <p>
  【新唐人北京时间2023年06月16日讯】人工智能的发展带来便利的同时也引发人们的担忧，
  <ok href="https://www.ntdtv.com/gb/ai.htm">
   AI
  </ok>
  的发展到底是福是祸，争议一直不断。全球知名公司Alphabet在全球推广自己的AI聊天机器人
  <ok href="https://www.ntdtv.com/gb/bard.htm">
   Bard
  </ok>
  ，却警告其内部员工谨慎使用。
 </p>
 <p>
  据路透社6月15日报导，4位知情人士称，
  <ok href="https://www.ntdtv.com/gb/谷歌.htm">
   谷歌
  </ok>
  母公司Alphabet已建议员工不要将他们的机密资料输入
  <ok href="https://www.ntdtv.com/gb/ai.htm">
   AI
  </ok>
  聊天机器人。
 </p>
 <p>
  这些聊天机器人，包括
  <ok href="https://www.ntdtv.com/gb/bard.htm">
   Bard
  </ok>
  和OpenAI开发的ChatGPT，使用所谓的生成人工智能与用户进行对话并回答问题。人类用户可能会阅读其聊天记录。研究人员发现，类似的AI可以重现它在训练期间吸收的数据，从而造成泄露风险。
 </p>
 <p>
  一些知情人士说，Alphabet还提醒其工程师，也不要直接使用聊天机器人生成的计算机代码。该公司表示，Bard可能会主动提出代码建议。
 </p>
 <p>
  <ok href="https://www.ntdtv.com/gb/谷歌.htm">
   谷歌
  </ok>
  还表示，它的目标是对其技术的局限性保持透明。
 </p>
 <p>
  这些担忧表明，谷歌希望为了与ChatGPT竞争而推出的软件不要造成商业损失。谷歌与ChatGPT开发者OpenAI以及微软公司的竞争，涉及到数十亿美元的投资，以及来自新AI程序的数不清的广告和云收入 。
 </p>
 <p>
  谷歌告诉路透社，全球越来越多的企业已经在AI聊天机器人上设置了护栏，包括三星、亚马逊和德意志银行。
 </p>
 <p>
  据报导，苹果公司没有回复评论请求，但也有类似限制。
 </p>
 <p>
  Fishbowl网站对大约12,000名受访者（包括总部位于美国的顶级公司）进行的一项调查表明，截至1月，大约43% 的专业人士正在使用ChatGPT或其它AI工具，而且通常没有告诉他们的老板。
 </p>
 <p>
  据Insider报导，早在2月份，谷歌就告诉测试Bard的员工，在发布前对其进行测试时，不要向其提供内部信息。随后警告扩展到其代码建议。
 </p>
 <p>
  现在，谷歌正在180多个国家或地区以40种语言推出Bard。
 </p>
 <p>
  谷歌告诉路透社，它已与爱尔兰数据保护委员会进行了详细对话，并正在解决监管机构的问题。
 </p>
 <h4>
  对
  <ok href="https://www.ntdtv.com/gb/敏感信息.htm">
   敏感信息
  </ok>
  的担忧
 </h4>
 <p>
  AI技术可以起草电子邮件、文件，甚至开发软件，能提高完成任务的速度。但是，此技术也可能包含虚假信息、敏感数据或《哈利波特》小说中受版权保护的内容段落。
 </p>
 <p>
  6月1日更新的谷歌隐私声明还说，“不要在与Bard的谈话中包含机密或
  <ok href="https://www.ntdtv.com/gb/敏感信息.htm">
   敏感信息
  </ok>
  。”
 </p>
 <p>
  一些公司开发了软件来解决这些问题。例如，保护网站免受网络攻击并提供其它云服务的Cloudflare，正在推出一项功能，让企业可以标记和限制某些数据向外部流动。
 </p>
 <p>
  谷歌和微软还向商业客户提供对话工具，这些工具价格很高，但可避免将数据吸收到公共AI模型中。Bard和ChatGPT中的默认设置是保存用户的对话历史记录，用户可以选择删除 。
 </p>
 <p>
  微软消费者首席营销官优素福·麦迪 （Yusuf Mehdi）表示，公司不希望员工使用公共聊天机器人工作是“有道理的”。
 </p>
 <p>
  “公司正在采取有条不紊的保守方法”，麦迪说。
 </p>
 <p>
  对于是否全面禁止员工将机密信息输入公共AI程序，包括它自己的程序，微软拒绝评论。
 </p>
 <p>
  Cloudflare首席执行官马修·普林斯 （Matthew Prince）表示，把机密信息输入聊天机器人，“就像让一群博士生随意处理你的所有私人记录”。
 </p>
 <p>
  （责任编辑：李郦）
 </p>
 <div class="single_ad">
 </div>
</div>
</div>
<hr/>
手机上长按并复制下列链接或二维码分享本文章：<br/>
https://github.com/gfw-breaker/banned-news3/blob/master/pages/prog203/a103732153.md <br/>
<a href='https://github.com/gfw-breaker/banned-news3/blob/master/pages/prog203/a103732153.md'><img src='https://github.com/gfw-breaker/banned-news3/blob/master/pages/prog203/a103732153.md.png'/></a> <br/>
原文地址（需翻墙访问）：https://www.ntdtv.com/gb/2023/06/15/a103732153.html


------------------------
#### [首页](https://github.com/gfw-breaker/banned-news3/blob/master/README.md) &nbsp;|&nbsp; [一键翻墙软件](https://github.com/gfw-breaker/nogfw/blob/master/README.md) &nbsp;| [《九评共产党》](https://github.com/gfw-breaker/9ping.md/blob/master/README.md#九评之一评共产党是什么) | [《解体党文化》](https://github.com/gfw-breaker/jtdwh.md/blob/master/README.md) | [《共产主义的终极目的》](https://github.com/gfw-breaker/gczydzjmd.md/blob/master/README.md)


<img src='http://gfw-breaker.win/banned-news3/pages/prog203/a103732153.md' width='0px' height='0px'/>